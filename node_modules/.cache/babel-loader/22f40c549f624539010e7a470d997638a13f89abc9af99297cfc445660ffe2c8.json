{"ast":null,"code":"import _extends from '@babel/runtime/helpers/esm/extends';\nimport * as THREE from 'three';\nimport * as React from 'react';\nimport { forwardRef, useRef, useState, useCallback, useMemo, useImperativeHandle, useEffect, Suspense, useContext, createContext } from 'react';\nimport { useThree, useFrame } from '@react-three/fiber';\nimport { easing } from 'maath';\nimport { suspend, clear } from 'suspend-react';\nimport { useVideoTexture } from './useVideoTexture.js';\nimport { Facemesh } from './Facemesh.js';\nimport { useFaceLandmarker } from './FaceLandmarker.js';\n\n// useVideoTexture 1st arg `src` type\n\nfunction mean(v1, v2) {\n  return v1.clone().add(v2).multiplyScalar(0.5);\n}\nfunction localToLocal(objSrc, v, objDst) {\n  // see: https://discourse.threejs.org/t/object3d-localtolocal/51564\n  const v_world = objSrc.localToWorld(v);\n  return objDst.worldToLocal(v_world);\n}\n\n//\n//\n//\nconst FaceControlsContext = /* @__PURE__ */createContext({});\nconst FaceControls = /* @__PURE__ */forwardRef((_ref, fref) => {\n  let {\n    camera,\n    autostart = true,\n    webcam = true,\n    webcamVideoTextureSrc,\n    manualUpdate = false,\n    manualDetect = false,\n    onVideoFrame,\n    smoothTime = 0.25,\n    offset = true,\n    offsetScalar = 80,\n    eyes = false,\n    eyesAsOrigin = true,\n    depth = 0.15,\n    debug = false,\n    facemesh,\n    makeDefault\n  } = _ref;\n  var _faces$facialTransfor, _faces$faceBlendshape;\n  const scene = useThree(state => state.scene);\n  const defaultCamera = useThree(state => state.camera);\n  const set = useThree(state => state.set);\n  const get = useThree(state => state.get);\n  const explCamera = camera || defaultCamera;\n  const webcamApiRef = useRef(null);\n  const facemeshApiRef = useRef(null);\n\n  //\n  // computeTarget()\n  //\n  // Compute `target` position and rotation for the camera (according to <Facemesh>)\n  //\n  //  1. ðŸ‘€ either following the 2 eyes\n  //  2. ðŸ‘¤ or just the head mesh\n  //\n\n  const [target] = useState(() => new THREE.Object3D());\n  const [irisRightDirPos] = useState(() => new THREE.Vector3());\n  const [irisLeftDirPos] = useState(() => new THREE.Vector3());\n  const [irisRightLookAt] = useState(() => new THREE.Vector3());\n  const [irisLeftLookAt] = useState(() => new THREE.Vector3());\n  const computeTarget = useCallback(() => {\n    // same parent as the camera\n    target.parent = explCamera.parent;\n    const facemeshApi = facemeshApiRef.current;\n    if (facemeshApi) {\n      const {\n        outerRef,\n        eyeRightRef,\n        eyeLeftRef\n      } = facemeshApi;\n      if (eyeRightRef.current && eyeLeftRef.current) {\n        // 1. ðŸ‘€\n\n        const {\n          irisDirRef: irisRightDirRef\n        } = eyeRightRef.current;\n        const {\n          irisDirRef: irisLeftDirRef\n        } = eyeLeftRef.current;\n        if (irisRightDirRef.current && irisLeftDirRef.current && outerRef.current) {\n          //\n          // position: mean of irisRightDirPos,irisLeftDirPos\n          //\n          irisRightDirPos.copy(localToLocal(irisRightDirRef.current, new THREE.Vector3(0, 0, 0), outerRef.current));\n          irisLeftDirPos.copy(localToLocal(irisLeftDirRef.current, new THREE.Vector3(0, 0, 0), outerRef.current));\n          target.position.copy(localToLocal(outerRef.current, mean(irisRightDirPos, irisLeftDirPos), explCamera.parent || scene));\n\n          //\n          // lookAt: mean of irisRightLookAt,irisLeftLookAt\n          //\n          irisRightLookAt.copy(localToLocal(irisRightDirRef.current, new THREE.Vector3(0, 0, 1), outerRef.current));\n          irisLeftLookAt.copy(localToLocal(irisLeftDirRef.current, new THREE.Vector3(0, 0, 1), outerRef.current));\n          target.lookAt(outerRef.current.localToWorld(mean(irisRightLookAt, irisLeftLookAt)));\n        }\n      } else {\n        // 2. ðŸ‘¤\n\n        if (outerRef.current) {\n          target.position.copy(localToLocal(outerRef.current, new THREE.Vector3(0, 0, 0), explCamera.parent || scene));\n          target.lookAt(outerRef.current.localToWorld(new THREE.Vector3(0, 0, 1)));\n        }\n      }\n    }\n    return target;\n  }, [explCamera, irisLeftDirPos, irisLeftLookAt, irisRightDirPos, irisRightLookAt, scene, target]);\n\n  //\n  // update()\n  //\n  // Updating the camera `current` position and rotation, following `target`\n  //\n\n  const [current] = useState(() => new THREE.Object3D());\n  const update = useCallback(function (delta, target) {\n    if (explCamera) {\n      var _target;\n      (_target = target) !== null && _target !== void 0 ? _target : target = computeTarget();\n      if (smoothTime > 0) {\n        // damping current\n        const eps = 1e-9;\n        easing.damp3(current.position, target.position, smoothTime, delta, undefined, undefined, eps);\n        easing.dampE(current.rotation, target.rotation, smoothTime, delta, undefined, undefined, eps);\n      } else {\n        // instant\n        current.position.copy(target.position);\n        current.rotation.copy(target.rotation);\n      }\n      explCamera.position.copy(current.position);\n      explCamera.rotation.copy(current.rotation);\n    }\n  }, [explCamera, computeTarget, smoothTime, current.position, current.rotation]);\n\n  //\n  // detect()\n  //\n\n  const [faces, setFaces] = useState();\n  const faceLandmarker = useFaceLandmarker();\n  const detect = useCallback((video, time) => {\n    const faces = faceLandmarker == null ? void 0 : faceLandmarker.detectForVideo(video, time);\n    setFaces(faces);\n  }, [faceLandmarker]);\n  useFrame((_, delta) => {\n    if (!manualUpdate) {\n      update(delta);\n    }\n  });\n\n  // Ref API\n  const api = useMemo(() => Object.assign(Object.create(THREE.EventDispatcher.prototype), {\n    detect,\n    computeTarget,\n    update,\n    facemeshApiRef,\n    webcamApiRef,\n    // shorthands\n    play: () => {\n      var _webcamApiRef$current;\n      (_webcamApiRef$current = webcamApiRef.current) == null || (_webcamApiRef$current = _webcamApiRef$current.videoTextureApiRef.current) == null || _webcamApiRef$current.texture.source.data.play();\n    },\n    pause: () => {\n      var _webcamApiRef$current2;\n      (_webcamApiRef$current2 = webcamApiRef.current) == null || (_webcamApiRef$current2 = _webcamApiRef$current2.videoTextureApiRef.current) == null || _webcamApiRef$current2.texture.source.data.pause();\n    }\n  }), [detect, computeTarget, update]);\n  useImperativeHandle(fref, () => api, [api]);\n\n  //\n  // events callbacks\n  //\n\n  useEffect(() => {\n    const onVideoFrameCb = e => {\n      if (!manualDetect) detect(e.texture.source.data, e.time);\n      if (onVideoFrame) onVideoFrame(e);\n    };\n    api.addEventListener('videoFrame', onVideoFrameCb);\n    return () => {\n      api.removeEventListener('videoFrame', onVideoFrameCb);\n    };\n  }, [api, detect, faceLandmarker, manualDetect, onVideoFrame]);\n\n  // `controls` global state\n  useEffect(() => {\n    if (makeDefault) {\n      const old = get().controls;\n      set({\n        controls: api\n      });\n      return () => set({\n        controls: old\n      });\n    }\n  }, [makeDefault, api, get, set]);\n  const points = faces == null ? void 0 : faces.faceLandmarks[0];\n  const facialTransformationMatrix = faces == null || (_faces$facialTransfor = faces.facialTransformationMatrixes) == null ? void 0 : _faces$facialTransfor[0];\n  const faceBlendshapes = faces == null || (_faces$faceBlendshape = faces.faceBlendshapes) == null ? void 0 : _faces$faceBlendshape[0];\n  return /*#__PURE__*/React.createElement(FaceControlsContext.Provider, {\n    value: api\n  }, webcam && /*#__PURE__*/React.createElement(Suspense, {\n    fallback: null\n  }, /*#__PURE__*/React.createElement(Webcam, {\n    ref: webcamApiRef,\n    autostart: autostart,\n    videoTextureSrc: webcamVideoTextureSrc\n  })), /*#__PURE__*/React.createElement(Facemesh, _extends({\n    ref: facemeshApiRef\n  }, facemesh, {\n    points: points,\n    depth: depth,\n    facialTransformationMatrix: facialTransformationMatrix,\n    faceBlendshapes: faceBlendshapes,\n    eyes: eyes,\n    eyesAsOrigin: eyesAsOrigin,\n    offset: offset,\n    offsetScalar: offsetScalar,\n    debug: debug,\n    \"rotation-z\": Math.PI,\n    visible: debug\n  }), /*#__PURE__*/React.createElement(\"meshBasicMaterial\", {\n    side: THREE.DoubleSide\n  })));\n});\nconst useFaceControls = () => useContext(FaceControlsContext);\n\n//\n// Webcam\n//\nconst Webcam = /* @__PURE__ */forwardRef((_ref2, fref) => {\n  let {\n    videoTextureSrc,\n    autostart = true\n  } = _ref2;\n  const videoTextureApiRef = useRef(null);\n  const faceControls = useFaceControls();\n  const stream = suspend(async () => {\n    return !videoTextureSrc ? await navigator.mediaDevices.getUserMedia({\n      audio: false,\n      video: {\n        facingMode: 'user'\n      }\n    }) : Promise.resolve(null);\n  }, [videoTextureSrc]);\n  useEffect(() => {\n    faceControls.dispatchEvent({\n      type: 'stream',\n      stream\n    });\n    return () => {\n      stream == null || stream.getTracks().forEach(track => track.stop());\n      clear([videoTextureSrc]);\n    };\n  }, [stream, faceControls, videoTextureSrc]);\n\n  // ref-api\n  const api = useMemo(() => ({\n    videoTextureApiRef\n  }), []);\n  useImperativeHandle(fref, () => api, [api]);\n  return /*#__PURE__*/React.createElement(Suspense, {\n    fallback: null\n  }, /*#__PURE__*/React.createElement(VideoTexture, {\n    ref: videoTextureApiRef,\n    src: videoTextureSrc || stream,\n    start: autostart\n  }));\n});\n\n//\n// VideoTexture\n//\nconst VideoTexture = /* @__PURE__ */forwardRef((_ref3, fref) => {\n  let {\n    src,\n    start\n  } = _ref3;\n  const texture = useVideoTexture(src, {\n    start\n  });\n  const video = texture.source.data;\n  const faceControls = useFaceControls();\n  const onVideoFrame = useCallback(time => {\n    faceControls.dispatchEvent({\n      type: 'videoFrame',\n      texture,\n      time\n    });\n  }, [texture, faceControls]);\n  useVideoFrame(video, onVideoFrame);\n\n  // ref-api\n  const api = useMemo(() => ({\n    texture\n  }), [texture]);\n  useImperativeHandle(fref, () => api, [api]);\n  return /*#__PURE__*/React.createElement(React.Fragment, null);\n});\nconst useVideoFrame = (video, f) => {\n  // https://web.dev/requestvideoframecallback-rvfc/\n  // https://www.remotion.dev/docs/video-manipulation\n  useEffect(() => {\n    if (!video || !video.requestVideoFrameCallback) return;\n    let handle;\n    function callback() {\n      f(...arguments);\n      handle = video.requestVideoFrameCallback(callback);\n    }\n    video.requestVideoFrameCallback(callback);\n    return () => video.cancelVideoFrameCallback(handle);\n  }, [video, f]);\n};\nexport { FaceControls, useFaceControls };","map":null,"metadata":{},"sourceType":"module","externalDependencies":[]}